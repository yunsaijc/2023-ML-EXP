{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从零实现线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用线性模型来生成一个数据集, 然后用线性回归模型来拟合这个数据集 (也就是恢复出线性模型的参数). \n",
    "\n",
    "即, 构造标签的真实值公式为: $y = Xw+b+\\epsilon$, 通过线性回归模型来拟合得到$\\hat{w},\\hat{b}$, (尽可能地) 恢复出参数$w$和$b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([-0.0985, -1.0528]) \n",
      "label: tensor([7.5952])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import LinearRegression as linear\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = linear.synthetic_data(true_w, true_b, 1000)\n",
    "print('features:', features[0], '\\nlabel:', labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3489,  0.7270],\n",
      "        [-0.5310,  1.0907],\n",
      "        [ 1.0167, -0.9754],\n",
      "        [ 0.5836, -0.3068],\n",
      "        [-0.0947, -0.5861],\n",
      "        [ 0.5534, -0.0115],\n",
      "        [-0.8351,  1.7758],\n",
      "        [ 0.4035,  0.1887],\n",
      "        [-0.0557, -1.5214],\n",
      "        [ 1.1420,  0.1773]]) \n",
      " tensor([[ 2.4133],\n",
      "        [-0.5602],\n",
      "        [ 9.5646],\n",
      "        [ 6.4233],\n",
      "        [ 5.9990],\n",
      "        [ 5.3507],\n",
      "        [-3.5125],\n",
      "        [ 4.3698],\n",
      "        [ 9.2586],\n",
      "        [ 5.8779]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "for X, y in linear.data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义/ 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型参数\n",
    "w, b = linear.init_params()\n",
    "# 定义模型\n",
    "net = linear.linreg\n",
    "# 定义损失函数\n",
    "loss = linear.squared_loss\n",
    "# 定义优化算法\n",
    "optimizer = linear.sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "完整流程: \n",
    "\n",
    "- 初始化模型参数\n",
    "- 重复直到完成:\n",
    "    - 计算模型在数据集上的输出\n",
    "    - 计算损失\n",
    "    - 优化 (即更新模型参数, 梯度反向传播)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.031734\n",
      "epoch 2, loss 0.000108\n",
      "epoch 3, loss 0.000051\n",
      "\n",
      "Diff between true_w and w: \n",
      " tensor([ 0.0005, -0.0005], grad_fn=<SubBackward0>)\n",
      "Diff between true_b and b: \n",
      " tensor([0.0003], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "lr, num_epochs = 0.03, 3\n",
    "linear.train_linreg(net, loss, optimizer, lr, num_epochs, batch_size, features, labels, w, b)\n",
    "\n",
    "print(\"\\nDiff between true_w and w: \\n\", true_w - w.reshape(true_w.shape))\n",
    "print(\"Diff between true_b and b: \\n\", true_b - b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
