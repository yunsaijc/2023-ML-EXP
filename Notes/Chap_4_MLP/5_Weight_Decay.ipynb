{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 权重衰减"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大量数据可以缓解过拟合，但成本高。\n",
    "\n",
    "正则化技术是缓解过拟合的另一种技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 权重衰减\n",
    "\n",
    "也被称为L2范数正则化，通过函数与零的距离来衡量函数的复杂度，向损失函数添加L2范数惩罚项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用L2范数的一个原因是：\n",
    "\n",
    "它对权重向量的大分量施加了巨大的惩罚。这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。\n",
    "\n",
    "相比之下，L1 惩罚会导致模型将权重集中在一小部分特征上，而将其他 权重清除为零。这称为特征选择(feature selection)，这可能是其他场景下需要的"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
